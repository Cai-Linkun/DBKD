lr: 0.00005
batch_size: 64
random_seed: 914
w2v_size: 100
metric: "f1_micro"
enc_dim: 100
label_dim: 100
epochs: 900
join_train: 1
droprate: 0.4
cls_threshold: 0.5
num_cls: 8921 # rewrite when load data
mode: 'debug' # release
max_words: 2500
val_interval: 50
log_interval: 10
lambda: 0.2
temperature: 2

# change when data changed: mimic full
c2ind: "./processed_data/c2ind.npy"
ind2c: "./processed_data/ind2c.npy"
hmidx: "./processed_data/hmidx.npy"
comatrix: "./processed_data/comatrix.npy"
hier_level_idx: "./processed_data/hier_level_idx.npy"
embedding: "./processed_data/processed_full.embed"
train_data: "./processed_data/train_ov_full.csv" # test | dev

persistent:
  feat: "./trained_models/feat.pth"
  clas: "./trained_models/clas.pth"
  stud: "./trained_models/stud.pth"
  dbkd: "./trained_models/dbkd.pth"

doc_enc:
  dense_layers: 5
  kernel_size: 3

label_enc:
  label_embeddings: "./processed_data/label_embeddings.pth"

bio_bert:
  layer: 12
  vector_size: 768
  head: 12
